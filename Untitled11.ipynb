{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "16uuINaFOPbkCdUbQjpTC-8USMxEGyfbC",
      "authorship_tag": "ABX9TyMjlSwf3o2RkJY2QfEo1r8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choijian/pracitce_gru/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA5X78PiEtqV"
      },
      "outputs": [],
      "source": [
        "import cupy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "n_time = 20     #시점 수\n",
        "n_mid = 128     #은닉층 뉴런 수\n",
        "eta = 0.01    #학습률\n",
        "clip_const = 0.02   #노릅의 최댓값을 구하는 상수\n",
        "beta = 2    #확률분포 폭\n",
        "epoch = 50\n",
        "batch_size = 128\n",
        "\n",
        "def sigmoid(x):   #시그모이드 함수 구현\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def clip_grad(grads, max_norm):    #그래디언트 클리핑 구현\n",
        "  norm = np.sqrt(np.sum(grads*grads))\n",
        "  r = max_norm / norm\n",
        "  if(r<1):\n",
        "    clipped_grads = grads * r\n",
        "  else:\n",
        "    clipped_grads = grads\n",
        "  return clipped_grads\n",
        "\n",
        "with open(\"shakespeare.txt\", \"r\", encoding = 'utf-8')as f:\n",
        "  text = f.read()\n",
        "print(\"문자 수: \", len(text))   #텍스트 내의 문자 수 출력\n",
        "\n",
        "chars_list = sorted(list(set(text)))    #문자에 인덱스 연결\n",
        "n_chars = len(chars_list)\n",
        "print(\"문자 수(중복 제외): \", n_chars)\n",
        "\n",
        "char_to_index = {}  #문자가 키이고 인덱스가 값인 딕셔너리\n",
        "index_to_char = {}  #인덱스가 키이고 문자가 값인 딕셔너리\n",
        "for i, char in enumerate(chars_list):\n",
        "  char_to_index[char] = i\n",
        "  index_to_char[i] = char\n",
        "\n",
        "seq_chars = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text)-n_time):\n",
        "  seq_chars.append(text[i:i+n_time])\n",
        "  next_chars.append(text[i+n_time])\n",
        "\n",
        "#입력과 정답을 원핫 인코딩으로 표시\n",
        "input_data = np.zeros((len(seq_chars), n_time, n_chars), dtype = np.bool)\n",
        "correct_data = np.zeros((len(seq_chars), n_chars), dtype=np.bool)\n",
        "\n",
        "#정답을 원핫 인코딩으로 표시\n",
        "for i, chars in enumerate(seq_chars):\n",
        "  correct_data[i,char_to_index[next_chars[i]]] = 1\n",
        "\n",
        "#입력을 원핫 인코딩으로 표시\n",
        "for j, char in enumerate(chars):\n",
        "  input_data[i,j,char_to_index[char]] = 1\n",
        "\n",
        "# ---GRU층---\n",
        "#A0 = 업데이트 게이트, A1 = 리셋 게이트, A2 = 새로운 기억\n",
        "#x:입력, y_prev:이전 시각의 출력, grad_y: 출력의 기울기\n",
        "#x,v: 가중치(행렬 3개를 포함한 배열), n_upper: 앞 신경망층의 뉴런 수\n",
        "#n: 해당 신경망 층의 뉴런 수\n",
        "\n",
        "class GRULayer:\n",
        "  #파라미터의 초깃값\n",
        "  def __init__(self, n_upper, n):\n",
        "    self.w = np.random.randn(3,n_upper,n) / np.sqrt(n_upper)\n",
        "    self.v = np.random.randn(3,n,n) // np.sqrt(n)\n",
        "\n",
        "  def forward(self,x,y_prev):\n",
        "  #업데이트 게이트\n",
        "    a0 = sigmoid(np.dot(x,self.w[0]) + np.dot(y_prev, self.v[0]))\n",
        "  #재설정 게이트\n",
        "    a1 = sigmoid(np.dot(x, self.w[1]) + np.dot(y_prev, self.v[1]))\n",
        "  #새로운 기억\n",
        "    a2 = np.tanh(np.dot(x, self.w[2]) + np.dot(y_prev, self.v[2]))\n",
        "    self.gates = np.stack((a0, a1, a2))\n",
        "    self.y = (1-a0)*y_prev + a0*a2  #출력\n",
        "\n",
        "  def backward(self, x, y, y_prev, gates, grad_y):\n",
        "    a0, a1, a2 = gates\n",
        "\n",
        "    #새로운 기억\n",
        "    delta_a2 = grad_y * a0 * (1-a2**2)\n",
        "    self.grad_w[2] += np.dot(x.T, delta_a2)\n",
        "    self.grad_v[2] += np.dot((a1*y_prev).T, delta_a2)\n",
        "\n",
        "    #업데이트 게이트\n",
        "    delta_a0 = grad_y * (a2-y_prev) * a0 * (1-a0)\n",
        "    self.grad_w[0] += np.dot(x.T, delta_a0)\n",
        "    self.grad_v[0] += np.dot(y_prev.T, delta_a0)\n",
        "\n",
        "    #리셋 게이트\n",
        "    s = np.dot(delta_a2, self.v[2].T)\n",
        "    delta_a1 = s * y_prev * a1 * (1-a1)\n",
        "    self.grad_w[1] += np.dot(x.T, delta_a1)\n",
        "    self.grad_v[1] += np.dot(y_prev.T, delta_a1)\n",
        "\n",
        "    #x의 기울기\n",
        "    self.grad_x = np.dot(delta_a0, self.w[0].T)\n",
        "    +np.dot(delta_a1, self.w[1].T)\n",
        "    +np.dot(delta_a2, self.w[2].T)\n",
        "\n",
        "    #y_prev의 기울기\n",
        "    self.grad_y_prev = np.dot(delta_a0, self.v[0].T)\n",
        "    +np.dot(delta_a1, self.v[1].T)\n",
        "    +a1*s + grad_y*(1-a0)\n",
        "\n",
        "  def reset_sum_grad(self):\n",
        "    self.grad_w = np.zeros_like(self.w)\n",
        "    self.grad_v = np.zeros_like(self.v)\n",
        "\n",
        "  def update(self, eta):\n",
        "    self.w -= eta * self.grad_w\n",
        "    self.v -= eta * self.grad_v\n",
        "\n",
        "#전결합 출력층\n",
        "class OutputLayer:\n",
        "  def __init__(self, n_upper, n):\n",
        "    #자비에르 초기화 기반의 초깃값\n",
        "    self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)\n",
        "    self.b = np.zeros(n)\n",
        "\n",
        "  def forward(self,x):\n",
        "    self.x = x\n",
        "    u = np.dot(x, self.w + self.b)\n",
        "    self.y = u\n",
        "\n",
        "  def backward(self, t):\n",
        "    delta = self.y - t\n",
        "    self.grad_w = np.dot(self.x.T, delta)\n",
        "    self.grad_b = np.sum(delta, axis=0)\n",
        "    self.grad_x = np.dot(delta, self.w.T)\n",
        "\n",
        "  def update(self, eta):\n",
        "    self.w -= eta * self.grad_w\n",
        "    self.b -= eta * self.grad_b\n",
        "\n",
        "#각 신경망층의 초기화\n",
        "gru_layer = GRULayer(n_chars, n_mid)\n",
        "output_layer = OutputLayer(n_mid, n_chars)\n",
        "\n",
        "# --훈련--\n",
        "def train(x_mb, t_mb):\n",
        "  #순전파 GRU층\n",
        "  y_rnn = np.zeros((len(x_mb), n_time+1, n_mid))\n",
        "  gates_rnn = np.zeros((3, len(x_mb), n_time, n_mid))\n",
        "  y_prev = y_rnn[:,0,:]\n",
        "  for i in range(n_time):\n",
        "    x = x_mb[:,i,:]\n",
        "    gru_layer.forward(x, y_prev)\n",
        "\n",
        "    y = gru_layer.y\n",
        "    y_rnn[:, i+1, :] = y\n",
        "    y_prev = y_prev\n",
        "\n",
        "    gates = gru_layer.gates\n",
        "    gates_rnn[:,:,i,:] = gates\n",
        "\n",
        "    #순전파 출력층\n",
        "    output_layer.forward(y)\n",
        "\n",
        "    #역전파 출력층\n",
        "    output_layer.backward(t_mb)\n",
        "    grad_y = output_layer.grad_x\n",
        "\n",
        "    #역전파 GRU층\n",
        "    gru_layer.reset_sum_grad()\n",
        "    for i in reversed(range(n_time)):\n",
        "      x = x_mb[:, i, :]\n",
        "      y = y_rnn[:, i+1, :]\n",
        "      y_prev = y_rnn[:, i, :]\n",
        "      gates = gates_rnn[:, :, i, :]\n",
        "\n",
        "      gru_layer.backward(x, y, y_prev, gates, grad_y)\n",
        "      grad_y = gru_layer.grad_y_prev\n",
        "\n",
        "    #파라미터 갱신\n",
        "    gru_layer.update(eta)\n",
        "    output_layer.update(eta)\n",
        "\n",
        "#예측\n",
        "def predict(x_mb):\n",
        "  #순전파 gru층\n",
        "  y_prev = np.zeros((len(x_mb), n_mid))\n",
        "  for i in range(n_time):\n",
        "    x = x_mb[:, i, :]\n",
        "    gru_layer.forward(x, y_prev)\n",
        "    y = gru_layer.y\n",
        "    y_prev = y\n",
        "\n",
        "  #순전파 출력층\n",
        "  output_layer.forward(y)\n",
        "  return output_layer.y\n",
        "\n",
        "#--오차계산--\n",
        "def get_error(x, t):\n",
        "  y = predict(x)\n",
        "  return 1.0/2.0 * np.sum(np.square(y-t)) #오차 제곱의 합\n",
        "\n",
        "def create_text():\n",
        "  prev_text = text[0:n_time]  #입력\n",
        "  created_text = prev_text    #생성되는 텍스트\n",
        "  print(\"SEED: \", created_text)\n",
        "\n",
        "  for i in range(200):    #200자 문자 생성\n",
        "    #입력을 원핫 인코딩으로 표시\n",
        "    x = np.zeros((1, n_time, n_chars))\n",
        "    for j, char in enumerate(prev_text):\n",
        "      x[0, j, char_to_index[char]] = 1\n",
        "\n",
        "    #다음 문자 예측\n",
        "    y = predict(x)\n",
        "    p = y[0] ** beta  #확률분포 조정\n",
        "    p = p / np.sum(p)   #p의 합을 1로\n",
        "    next_index = np.random.choice(len(p), size=1, p=p)\n",
        "    next_char = index_to_char[int(next_index[0])]\n",
        "    created_text += next_char\n",
        "    prev_text = prev_text[1:] + next_char\n",
        "\n",
        "  print(created_text)\n",
        "  print()   #개행\n",
        "\n",
        "error_record = []\n",
        "n_batch = len(input_data) // batch_size     #1에포크당 배치 개수\n",
        "\n",
        "for i in range(epoch):\n",
        "  #--학습--\n",
        "  index_random = np.arange(len(input_data))\n",
        "  np.random.shuffle(index_random)\n",
        "  for j in range(n_batch):\n",
        "      #미니 배치 구성\n",
        "      mb_index = index_random[j*batch_size : (j+1)*batch_size]\n",
        "      x_mb = input_data[mb_index, :]\n",
        "      t_mb = correct_data[mb_index, :]\n",
        "      train(x_mb, t_mb)\n",
        "\n",
        "      #--경과 표시--\n",
        "      print(\"\\rEpoch: \"+str(i+1)+\"/\"+str(epoch)+\" \"+str(j+1)+\"/\"+str(n_batch), end=\"\")\n",
        "\n",
        "      #--오차 계산--\n",
        "      error = get_error(input_data, correct_data)\n",
        "      error_record.append(error)\n",
        "      print(\"\\rError: \"+str(error))\n",
        "\n",
        "      #경과표시\n",
        "      create_text()\n",
        "\n",
        "plt.plot(range(1, len(error_record)+1), error_record, label=\"error\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}